import numpy as np
import pandas as pd
import joblib
import torch
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score,
    precision_score, recall_score, confusion_matrix,
    classification_report, roc_curve
)
import matplotlib.pyplot as plt
import seaborn as sns
from config_gpu import config
from utils_gpu import load_gpu_features, extract_stylometric_features_gpu
from perplexity_gpu import get_perplexity_calculator
from transformations_gpu import get_transformations


class HSSEDetectorGPU:
    """–§–∏–Ω–∞–ª—å–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä HSSE —Å GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π."""

    def __init__(self):
        print("üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è HSSE –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞...")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        self.meta_model = joblib.load(config.META_MODEL_PATH)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –º–æ–¥–µ–ª—å
        from transformers import AutoTokenizer, AutoModelForSequenceClassification
        self.semantic_tokenizer = AutoTokenizer.from_pretrained(config.SEMANTIC_MODEL_PATH)
        self.semantic_model = AutoModelForSequenceClassification.from_pretrained(
            config.SEMANTIC_MODEL_PATH
        ).to(config.DEVICE)
        self.semantic_model.eval()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∏–ª–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫—É—é –º–æ–¥–µ–ª—å
        self.stylometric_model = joblib.load(config.STYLOMETRIC_MODEL_PATH)
        self.stylometric_scaler = joblib.load(config.STYLOMETRIC_SCALER_PATH)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–ø–ª–µ–∫—Å–∏—é –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.perplexity_calc = get_perplexity_calculator()
        self.transformator = get_transformations()

        print("‚úÖ HSSE –¥–µ—Ç–µ–∫—Ç–æ—Ä –≥–æ—Ç–æ–≤!")

    def extract_features(self, text: str) -> np.ndarray:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ 4 –ø—Ä–∏–∑–Ω–∞–∫–∞ HSSE –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        features = []

        # 1. Semantic Score
        encoding = self.semantic_tokenizer(
            text,
            max_length=config.MAX_LENGTH,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )

        with torch.no_grad():
            input_ids = encoding['input_ids'].to(config.DEVICE)
            attention_mask = encoding['attention_mask'].to(config.DEVICE)

            if config.USE_AMP:
                with torch.cuda.amp.autocast():
                    outputs = self.semantic_model(input_ids=input_ids, attention_mask=attention_mask)
            else:
                outputs = self.semantic_model(input_ids=input_ids, attention_mask=attention_mask)

            probs = torch.softmax(outputs.logits, dim=1)
            p_sem = probs[0, 1].item()

        features.append(p_sem)

        # 2. Stylometric Score
        style_features = extract_stylometric_features_gpu(text)
        style_vector = np.array([style_features[feat] for feat in config.STYLOMETRIC_FEATURES]).reshape(1, -1)
        style_vector_scaled = self.stylometric_scaler.transform(style_vector)
        p_sty = self.stylometric_model.predict_proba(style_vector_scaled)[0, 1]
        features.append(p_sty)

        # 3. Perplexity Gap
        delta_ppl = self.perplexity_calc.calculate_perplexity_gap(text)
        delta_ppl_norm = np.clip(delta_ppl, -5, 5) / 10.0
        features.append(delta_ppl_norm)

        # 4. Stability Score
        transformed_texts = self.transformator.apply_transformations(text, config.N_TRANSFORMATIONS)
        all_probs = [p_sem]

        for transformed_text in transformed_texts:
            try:
                encoding = self.semantic_tokenizer(
                    transformed_text,
                    max_length=config.MAX_LENGTH,
                    padding='max_length',
                    truncation=True,
                    return_tensors='pt'
                )

                with torch.no_grad():
                    input_ids = encoding['input_ids'].to(config.DEVICE)
                    attention_mask = encoding['attention_mask'].to(config.DEVICE)

                    if config.USE_AMP:
                        with torch.cuda.amp.autocast():
                            outputs = self.semantic_model(input_ids=input_ids, attention_mask=attention_mask)
                    else:
                        outputs = self.semantic_model(input_ids=input_ids, attention_mask=attention_mask)

                    probs = torch.softmax(outputs.logits, dim=1)
                    prob = probs[0, 1].item()
                    all_probs.append(prob)
            except:
                continue

        stability = np.var(all_probs) if len(all_probs) > 1 else 0.0
        features.append(stability)

        return np.array(features)

    def predict(self, text: str, return_proba: bool = False):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç AI-generated.

        Args:
            text: –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
            return_proba: –µ—Å–ª–∏ True, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å

        Returns:
            prediction (0/1) –∏–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        """
        features = self.extract_features(text).reshape(1, -1)
        proba = self.meta_model.predict_proba(features)[0, 1]

        if return_proba:
            return proba
        else:
            return 1 if proba > 0.5 else 0

    def predict_batch(self, texts: list, batch_size: int = 32):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –±–∞—Ç—á–∞ —Ç–µ–∫—Å—Ç–æ–≤."""
        results = []

        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            for text in batch_texts:
                proba = self.predict(text, return_proba=True)
                results.append({
                    'text': text[:100] + '...' if len(text) > 100 else text,
                    'probability': proba,
                    'prediction': 'AI' if proba > 0.5 else 'Human',
                    'confidence': 'High' if abs(proba - 0.5) > 0.3 else
                    'Medium' if abs(proba - 0.5) > 0.1 else 'Low'
                })

        return results


def evaluate_hsse_gpu():
    """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ HSSE –º–µ—Ç–æ–¥–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    print("=" * 70)
    print("üéØ HSSE - –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê –ù–ê GPU")
    print("=" * 70)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    test_data = load_gpu_features("hsse_test")

    X_test = test_data['X']
    y_test = test_data['y']

    print(f"–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {X_test.shape}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    meta_model = joblib.load(config.META_MODEL_PATH)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    print("\nüîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    y_pred = meta_model.predict(X_test)
    y_proba = meta_model.predict_proba(X_test)[:, 1]

    # –ú–µ—Ç—Ä–∏–∫–∏
    print("\n" + "=" * 50)
    print("üìä –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ HSSE")
    print("=" * 50)

    metrics = {
        'Accuracy': accuracy_score(y_test, y_pred),
        'F1 Score': f1_score(y_test, y_pred),
        'AUC ROC': roc_auc_score(y_test, y_proba),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred)
    }

    for name, value in metrics.items():
        print(f"  {name}: {value:.4f}")

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Human', 'AI'],
                yticklabels=['Human', 'AI'])
    plt.title('Confusion Matrix - HSSE Final Evaluation')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.savefig(config.MODELS_DIR / "hsse_final_confusion_matrix.png", dpi=100)
    plt.show()

    # ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_proba)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f'HSSE (AUC = {metrics["AUC ROC"]:.4f})', linewidth=2)
    plt.plot([0, 1], [0, 1], 'k--', label='Random')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve - HSSE Method')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(config.MODELS_DIR / "hsse_roc_curve.png", dpi=100)
    plt.show()

    # Classification report
    print("\nüìã Classification Report:")
    print(classification_report(y_test, y_pred, target_names=['Human', 'AI']))

    return metrics


def ablation_study_gpu():
    """Ablation study –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–∫–ª–∞–¥–∞ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ HSSE."""
    print("\n" + "=" * 70)
    print("üî¨ HSSE - ABLATION STUDY")
    print("=" * 70)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    test_data = load_gpu_features("hsse_test")
    X_test = test_data['X']
    y_test = test_data['y']

    feature_names = ['Semantic', 'Stylometric', 'Perplexity Gap', 'Stability']

    # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
    meta_model = joblib.load(config.META_MODEL_PATH)
    y_pred_full = meta_model.predict(X_test)
    f1_full = f1_score(y_test, y_pred_full)
    auc_full = roc_auc_score(y_test, meta_model.predict_proba(X_test)[:, 1])

    print(f"\nüìä –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–≤—Å–µ 4 –ø—Ä–∏–∑–Ω–∞–∫–∞):")
    print(f"  F1 Score: {f1_full:.4f}")
    print(f"  AUC ROC:  {auc_full:.4f}")

    print("\nüìâ Ablation Study (–±–µ–∑ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞):")

    for i in range(4):
        # –£–¥–∞–ª—è–µ–º –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫
        X_reduced = np.delete(X_test, i, axis=1)

        # –û–±—É—á–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –Ω–∞ —É–º–µ–Ω—å—à–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
        from lightgbm import LGBMClassifier

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        train_data = load_gpu_features("hsse_train")
        X_train_reduced = np.delete(train_data['X'], i, axis=1)
        y_train = train_data['y']

        # –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ
        model = LGBMClassifier(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            random_state=42,
            n_jobs=-1
        )

        model.fit(X_train_reduced, y_train)

        # –û—Ü–µ–Ω–∫–∞
        y_pred_reduced = model.predict(X_reduced)
        y_proba_reduced = model.predict_proba(X_reduced)[:, 1]

        f1_reduced = f1_score(y_test, y_pred_reduced)
        auc_reduced = roc_auc_score(y_test, y_proba_reduced)

        print(f"\n  –ë–µ–∑ {feature_names[i]}:")
        print(f"    F1 Score: {f1_reduced:.4f} (Œî = {f1_full - f1_reduced:+.4f})")
        print(f"    AUC ROC:  {auc_reduced:.4f} (Œî = {auc_full - auc_reduced:+.4f})")

        # –ï—Å–ª–∏ –ø–∞–¥–µ–Ω–∏–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ, –ø—Ä–∏–∑–Ω–∞–∫ –≤–∞–∂–µ–Ω
        if f1_full - f1_reduced > 0.05:
            print(f"    ‚ö†Ô∏è  {feature_names[i]} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω!")


if __name__ == "__main__":
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    metrics = evaluate_hsse_gpu()

    # Ablation study
    ablation_study_gpu()

    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
    print("\n" + "=" * 70)
    print("üé≠ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø HSSE –î–ï–¢–ï–ö–¢–û–†–ê")
    print("=" * 70)

    detector = HSSEDetectorGPU()

    # –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤
    examples = [
        "I was walking to the store when I saw a really cute dog. It was barking at a squirrel in a tree.",
        "The optimization of machine learning algorithms requires careful consideration of hyperparameter tuning to achieve optimal performance metrics.",
        "Yesterday, my friend and I went to see a movie. The theater was pretty crowded, but we still managed to get good seats.",
        "The implementation of deep neural networks necessitates the utilization of gradient-based optimization techniques for effective parameter estimation."
    ]

    for i, text in enumerate(examples, 1):
        result = detector.predict(text, return_proba=True)
        print(f"\n–ü—Ä–∏–º–µ—Ä {i}:")
        print(f"  –¢–µ–∫—Å—Ç: {text[:60]}...")
        print(f"  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å AI: {result:.3f}")
        print(f"  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {'ü§ñ AI-—Ç–µ–∫—Å—Ç' if result > 0.5 else 'üë§ –ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç'}")
        print(
            f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {'–í—ã—Å–æ–∫–∞—è' if abs(result - 0.5) > 0.3 else '–°—Ä–µ–¥–Ω—è—è' if abs(result - 0.5) > 0.1 else '–ù–∏–∑–∫–∞—è'}")